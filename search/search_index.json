{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Amateur blog This is the first blog I write. I would like to organize my ideas and my research projects. Topics Signal Processing mainly focused on Audio (part of my PhD work) Machine learning, with special focus on Deep learning Programming: Python, tensorflow, keras, matlab, ... Earth Science Interesting links about: Deep learning: How to fool a neural network link Deep learning from first principles in Python, R and octave link Deep learning with Python tutorial Tensorflow 2.0 + keras overview colab link Introduction to deep learning course at MIT Link Interpretability in Neural Networks link Visualization youtube Deep Learning + Audio + Python link Deep Learning from scratch link For music, teaching materials link Programming: A brief history of programming Languages link Object-oriented programming explained link Pytorch getting started tutorial Statistics: Best books for learning modern statistics link Bayes' theorem youtube link Bayesian optimization link Machine learning: Notebooks link Getting started in ML Audio Github Link Effective testing blog","title":"Home"},{"location":"#amateur-blog","text":"This is the first blog I write. I would like to organize my ideas and my research projects.","title":"Amateur blog"},{"location":"#topics","text":"Signal Processing mainly focused on Audio (part of my PhD work) Machine learning, with special focus on Deep learning Programming: Python, tensorflow, keras, matlab, ... Earth Science","title":"Topics"},{"location":"#interesting-links-about","text":"Deep learning: How to fool a neural network link Deep learning from first principles in Python, R and octave link Deep learning with Python tutorial Tensorflow 2.0 + keras overview colab link Introduction to deep learning course at MIT Link Interpretability in Neural Networks link Visualization youtube Deep Learning + Audio + Python link Deep Learning from scratch link For music, teaching materials link Programming: A brief history of programming Languages link Object-oriented programming explained link Pytorch getting started tutorial Statistics: Best books for learning modern statistics link Bayes' theorem youtube link Bayesian optimization link Machine learning: Notebooks link Getting started in ML Audio Github Link Effective testing blog","title":"Interesting links about:"},{"location":"about/","text":"My Background","title":"About"},{"location":"about/#my-background","text":"","title":"My Background"},{"location":"audio/audio_analysis/","text":"Analysing stream of audio data: Use of fixed-length batches during training. Long-short term memory (LSTM) cells to learn temporal relationships. Length variability of intra- and inter-class sound events: Short audio files \u2192 Zero-padded or replicate. Long audio files \u2192 Trim. Summarization strategies to aggregate temporal information at the output. Training and testing mismatch Training: perfectly isolated + supervised annotation process. Testing: real-world conditions: Variable-length segments. Weakly segmented events: only the presence of the events are indicated. Background noise. Weak labels Automatically obtained from the metadata on the web. Such labels are always expected to be noisy due to human semantic interpretation.","title":"Analysis"},{"location":"audio/audio_analysis/#analysing-stream-of-audio-data","text":"Use of fixed-length batches during training. Long-short term memory (LSTM) cells to learn temporal relationships.","title":"Analysing stream of audio data:"},{"location":"audio/audio_analysis/#length-variability-of-intra-and-inter-class-sound-events","text":"Short audio files \u2192 Zero-padded or replicate. Long audio files \u2192 Trim. Summarization strategies to aggregate temporal information at the output.","title":"Length variability of intra- and inter-class sound events:"},{"location":"audio/audio_analysis/#training-and-testing-mismatch","text":"Training: perfectly isolated + supervised annotation process. Testing: real-world conditions: Variable-length segments. Weakly segmented events: only the presence of the events are indicated. Background noise.","title":"Training and testing mismatch"},{"location":"audio/audio_analysis/#weak-labels","text":"Automatically obtained from the metadata on the web. Such labels are always expected to be noisy due to human semantic interpretation.","title":"Weak labels"},{"location":"audio/feature_rep/","text":"Signal Processing Techniques Windowing Choose of the window size: It is a trade-off, large window gives a good frequency resolution but poor time resolution. Music signals usually require bigger window size in order to resolve tones closely spaced in frequency. Constant Overlap Add (COLA) condition has to be satisfied in order to get the perfect reconstruction of the provided signal. Only prediodic window functions (Hamming, Hann)are COLA windows. Gabor Filter Linear filter. Band-pass filter for unidimensional signals Gammatone A band-pass filter approximates the frequency selectivity of a haircell site on the basilar membrane in the cochlea. It has: Monotone carrier, the tone. An envelope, gamma distribution function. Linear-frequency log-magnitude spectrogram Mel-frequency log-magnitude spectrogram","title":"Features"},{"location":"audio/feature_rep/#signal-processing-techniques","text":"","title":"Signal Processing Techniques"},{"location":"audio/feature_rep/#windowing","text":"Choose of the window size: It is a trade-off, large window gives a good frequency resolution but poor time resolution. Music signals usually require bigger window size in order to resolve tones closely spaced in frequency. Constant Overlap Add (COLA) condition has to be satisfied in order to get the perfect reconstruction of the provided signal. Only prediodic window functions (Hamming, Hann)are COLA windows.","title":"Windowing"},{"location":"audio/feature_rep/#gabor-filter","text":"Linear filter. Band-pass filter for unidimensional signals","title":"Gabor Filter"},{"location":"audio/feature_rep/#gammatone","text":"A band-pass filter approximates the frequency selectivity of a haircell site on the basilar membrane in the cochlea. It has: Monotone carrier, the tone. An envelope, gamma distribution function.","title":"Gammatone"},{"location":"audio/feature_rep/#linear-frequency-log-magnitude-spectrogram","text":"","title":"Linear-frequency log-magnitude spectrogram"},{"location":"audio/feature_rep/#mel-frequency-log-magnitude-spectrogram","text":"","title":"Mel-frequency log-magnitude spectrogram"},{"location":"audio/future_ideas/","text":"Future ideas / projects Can machine learning approaches learn from human uncertainty? How much noise, uncertainty, adds to the data? Types of uncertainty Human annotation: onset and offset identification, image segmentation annotation ...","title":"Future ideas / projects"},{"location":"audio/future_ideas/#future-ideas-projects","text":"Can machine learning approaches learn from human uncertainty? How much noise, uncertainty, adds to the data?","title":"Future ideas / projects"},{"location":"audio/future_ideas/#types-of-uncertainty","text":"Human annotation: onset and offset identification, image segmentation annotation ...","title":"Types of uncertainty"},{"location":"audio/info/","text":"Audio concepts Here I will describe the main concept for audio analysis. CASA Computer Auditory System Analysis ASR Automatic Speech Recognition LMSpec Log Mel-Spectrogram EPSI Equal-Performance Increase in dB SNR IBM Ideal Binary Mask MRCG Multi-Resolution CochleaGram ARMA Auto-Regressive Moving Average NMF Non-Negative Matrix Factorization Auditory modeling Outer ear: Pinna Middle ear: Eardrum (Hammer, anvil and Stirrup) Inner ear: Cochlea (Neural connections) The cochlea acts as a spectral analyzer, maps sound wave frequency onto specific membrane locations. The cochleogram : first stage of CASA processing. Creates a time-frequency representation. The signal is broken into different frequencies that are naturally selected by the cochlea and hair cells. A Filterbank (Gammatone Filter) is used to model the membrane. Maps cochlear place to the vertical axis Spectrogram : maps frequency to the vertical axis The correlogram : summarizes the information in the auditory firings using the autocorrelation of each cochlear channel. Components and properties Tone: is characterized by its duration , pitch , intensity (or loudness ) and timbre (or quality ). Pitch: subjective perception of the sound. Tonal height, distinguishes high sounds from low sounds. Timbre: sound quality from each sound, it allows to distinguish the object that produces the sound. Human range of hearing is limited from 20Hz (ultra-low sounds) to 25000Hz (ultra-high sounds) Human speech range between 100Hz and 8kHz","title":"Intro"},{"location":"audio/info/#audio-concepts","text":"Here I will describe the main concept for audio analysis. CASA Computer Auditory System Analysis ASR Automatic Speech Recognition LMSpec Log Mel-Spectrogram EPSI Equal-Performance Increase in dB SNR IBM Ideal Binary Mask MRCG Multi-Resolution CochleaGram ARMA Auto-Regressive Moving Average NMF Non-Negative Matrix Factorization","title":"Audio concepts"},{"location":"audio/info/#auditory-modeling","text":"Outer ear: Pinna Middle ear: Eardrum (Hammer, anvil and Stirrup) Inner ear: Cochlea (Neural connections) The cochlea acts as a spectral analyzer, maps sound wave frequency onto specific membrane locations. The cochleogram : first stage of CASA processing. Creates a time-frequency representation. The signal is broken into different frequencies that are naturally selected by the cochlea and hair cells. A Filterbank (Gammatone Filter) is used to model the membrane. Maps cochlear place to the vertical axis Spectrogram : maps frequency to the vertical axis The correlogram : summarizes the information in the auditory firings using the autocorrelation of each cochlear channel.","title":"Auditory modeling"},{"location":"audio/info/#components-and-properties","text":"Tone: is characterized by its duration , pitch , intensity (or loudness ) and timbre (or quality ). Pitch: subjective perception of the sound. Tonal height, distinguishes high sounds from low sounds. Timbre: sound quality from each sound, it allows to distinguish the object that produces the sound. Human range of hearing is limited from 20Hz (ultra-low sounds) to 25000Hz (ultra-high sounds) Human speech range between 100Hz and 8kHz","title":"Components and properties"},{"location":"audio/labels/","text":"Labeling Binary-class classification Only two classes are available. The sigmoid activation function is usually chosen. Multi-class classification When there are more than two classes but only one can be right, they are mutually exclusive. Then, the softmax activation function is the right choice. Single-label classification The output can belong only to one label, then a single softmax activation function is needed. With this approach a single distribution across all classes is learned. Multi-label classification There are more than two labels, and there are non-exclusive, meaning that more than one label can be right for the same input. In this scenario multiple sigmoid activation function are needed (each per class). Note All multi-label are multi-class classifiers. But not all multi-class classifiers are multi-label classifiers.","title":"Labels"},{"location":"audio/labels/#labeling","text":"","title":"Labeling"},{"location":"audio/labels/#binary-class-classification","text":"Only two classes are available. The sigmoid activation function is usually chosen.","title":"Binary-class classification"},{"location":"audio/labels/#multi-class-classification","text":"When there are more than two classes but only one can be right, they are mutually exclusive. Then, the softmax activation function is the right choice.","title":"Multi-class classification"},{"location":"audio/labels/#single-label-classification","text":"The output can belong only to one label, then a single softmax activation function is needed. With this approach a single distribution across all classes is learned.","title":"Single-label classification"},{"location":"audio/labels/#multi-label-classification","text":"There are more than two labels, and there are non-exclusive, meaning that more than one label can be right for the same input. In this scenario multiple sigmoid activation function are needed (each per class). Note All multi-label are multi-class classifiers. But not all multi-class classifiers are multi-label classifiers.","title":"Multi-label classification"},{"location":"audio/metrics/","text":"Metrics for acustic signals Mean opinion scores (MOS) Cosine similarity Loss functions Categorical cross entropy (CCE) Commonly used for multi-class classification. The predictions that differ more from the target labels are weighed more for the gradient update. Mean absolute error (MAE) Weighs all the predictions equally","title":"Metrics for acustic signals"},{"location":"audio/metrics/#metrics-for-acustic-signals","text":"Mean opinion scores (MOS) Cosine similarity","title":"Metrics for acustic signals"},{"location":"audio/metrics/#loss-functions","text":"Categorical cross entropy (CCE) Commonly used for multi-class classification. The predictions that differ more from the target labels are weighed more for the gradient update. Mean absolute error (MAE) Weighs all the predictions equally","title":"Loss functions"},{"location":"audio/problems/","text":"Acoustic problems Noise stationary: air conditioner, crowd speaking, wind, sea waves, constant background non-stationary: keyboard, scream, siren, alarm Reverberation","title":"Acoustic problems"},{"location":"audio/problems/#acoustic-problems","text":"","title":"Acoustic problems"},{"location":"audio/problems/#noise","text":"stationary: air conditioner, crowd speaking, wind, sea waves, constant background non-stationary: keyboard, scream, siren, alarm","title":"Noise"},{"location":"audio/problems/#reverberation","text":"","title":"Reverberation"},{"location":"audio/python/","text":"Audio with Python Library for playing vector with audio data: sounddevice . If we want to read audio from file we have first to import: soundfile module , before was called pysoundfile . Package for Music and Audio Analysis: librosa (Laboratory for the recognition and organization of speech and audio, Columbia University). Most common modules within this library: core features util","title":"Python"},{"location":"audio/python/#audio-with-python","text":"Library for playing vector with audio data: sounddevice . If we want to read audio from file we have first to import: soundfile module , before was called pysoundfile . Package for Music and Audio Analysis: librosa (Laboratory for the recognition and organization of speech and audio, Columbia University). Most common modules within this library: core features util","title":"Audio with Python"},{"location":"audio/taxonomy/","text":"Annotation of audio events Taxonomy Term used in biology for classifying species. Representation of categorical data in a hierarchy (whose naturally fitting data structure is a tree), each element of the taxonomy is a taxonomy node . In order to represent it using a human-readable format we can use: JSON Ontology \" A specification of a conceptualization\". Description of the concepts and relationships that can exist for an agent or a community of agents. Terminology enrichment - insertion of new concepts Fine-tuning from BERT model to insert new concept into a terminology's hierarchy.","title":"Taxonomy"},{"location":"audio/taxonomy/#annotation-of-audio-events","text":"","title":"Annotation of audio events"},{"location":"audio/taxonomy/#taxonomy","text":"Term used in biology for classifying species. Representation of categorical data in a hierarchy (whose naturally fitting data structure is a tree), each element of the taxonomy is a taxonomy node . In order to represent it using a human-readable format we can use: JSON","title":"Taxonomy"},{"location":"audio/taxonomy/#ontology","text":"\" A specification of a conceptualization\". Description of the concepts and relationships that can exist for an agent or a community of agents.","title":"Ontology"},{"location":"audio/taxonomy/#terminology-enrichment-insertion-of-new-concepts","text":"Fine-tuning from BERT model to insert new concept into a terminology's hierarchy.","title":"Terminology enrichment - insertion of new concepts"},{"location":"audio/trace/","text":"Trace-segmentation pooling layer Pooling layer based on a non-linear transformation of the learned convolutuional feature maps on the temporal axis. Uniform distance subsampling criterion is followed. TRACE = The temporal evolution of an audio event can be asumed to create a trajectory in the W-dimensional feature space. The trace can be computed from the magnitude of layer activations.","title":"Trace-segmentation pooling layer"},{"location":"audio/trace/#trace-segmentation-pooling-layer","text":"Pooling layer based on a non-linear transformation of the learned convolutuional feature maps on the temporal axis. Uniform distance subsampling criterion is followed. TRACE = The temporal evolution of an audio event can be asumed to create a trajectory in the W-dimensional feature space. The trace can be computed from the magnitude of layer activations.","title":"Trace-segmentation pooling layer"},{"location":"audio/transfer/","text":"Transfer learning Pre-trained models U-Net deep convolutional network SoundNet End to end convolutional network, trained using videos from Flickr. 2M unlabeled videos, with student-teacher training using ImageNet and Places CNN as a teacher. VGGish An audio embedding produced by training a modified VGGNet model to predict video tags from the Youtube-8M dataset. L3Net Trains a model taking the image (1 frame 224x224) and audio (1 second) from the same (matched) or from different (mismatched) videos. Original paper \"Look, listen and learn\" Github: Python, tensorflow 1.13, keras 2.0, kapre 0.1.4 (keras audio processors) BERT Bidirectional Encoder Representation from Transformers. Uses two techniques Masked LM (MLM) : randomly mask words in the sentence and then predict them. Next Sentence Prediction (NSP) : input pairs of sentences, learns to predict if the second is the next sentence. Tutorial with colab using pytorch + huggingFace library by Chris McCornick. Transformer-based language models Transformers are used to build language models where the embeddings can be retrieved as the by-product of pretraining. List of state-of-the-art transformers models: Transformer (google brain/research) BERT GPT-2 now GPT-3 (OpenAI) XLNet (Google brain) CTRL (SalesForce) Megatron (Nvidia) Turing-NLG (Microsoft)","title":"Transfer Learning"},{"location":"audio/transfer/#transfer-learning","text":"Pre-trained models U-Net deep convolutional network","title":"Transfer learning"},{"location":"audio/transfer/#soundnet","text":"End to end convolutional network, trained using videos from Flickr. 2M unlabeled videos, with student-teacher training using ImageNet and Places CNN as a teacher.","title":"SoundNet"},{"location":"audio/transfer/#vggish","text":"An audio embedding produced by training a modified VGGNet model to predict video tags from the Youtube-8M dataset.","title":"VGGish"},{"location":"audio/transfer/#l3net","text":"Trains a model taking the image (1 frame 224x224) and audio (1 second) from the same (matched) or from different (mismatched) videos. Original paper \"Look, listen and learn\" Github: Python, tensorflow 1.13, keras 2.0, kapre 0.1.4 (keras audio processors)","title":"L3Net"},{"location":"audio/transfer/#bert","text":"Bidirectional Encoder Representation from Transformers. Uses two techniques Masked LM (MLM) : randomly mask words in the sentence and then predict them. Next Sentence Prediction (NSP) : input pairs of sentences, learns to predict if the second is the next sentence. Tutorial with colab using pytorch + huggingFace library by Chris McCornick.","title":"BERT"},{"location":"audio/transfer/#transformer-based-language-models","text":"Transformers are used to build language models where the embeddings can be retrieved as the by-product of pretraining. List of state-of-the-art transformers models: Transformer (google brain/research) BERT GPT-2 now GPT-3 (OpenAI) XLNet (Google brain) CTRL (SalesForce) Megatron (Nvidia) Turing-NLG (Microsoft)","title":"Transformer-based language models"},{"location":"audio/speech/intro/","text":"Speech signal processing Speech recognition Hybrid approach by Facebook research link CTC (Connectionist Temporal Classification) Tutorial for sequence modeling with CTC, an algorithm used to train deep neural networks in speech recognition, handwriting recognition and other sequence problems. Link here","title":"-Speech processing"},{"location":"audio/speech/intro/#speech-signal-processing","text":"","title":"Speech signal processing"},{"location":"audio/speech/intro/#speech-recognition","text":"Hybrid approach by Facebook research link","title":"Speech recognition"},{"location":"audio/speech/intro/#ctc-connectionist-temporal-classification","text":"Tutorial for sequence modeling with CTC, an algorithm used to train deep neural networks in speech recognition, handwriting recognition and other sequence problems. Link here","title":"CTC (Connectionist Temporal Classification)"},{"location":"code/info/","text":"CODE JAX Autograd and XLA toguether for high-performance machine learning research. With Autograd Automatically differentiate native Python and NumPy functions. grad = Supports reverse mode differentiation (backpropagation) With XLA Compile and run NumPy programs on GPUs and TPUs. Compilation under the hood by default. Tensorflow tf.GradientTape(): For automatic differentiation computing the gradient of a computation with respect to its input variables. \"Tape\" records all the operations executed. Import the necessary packages import tensorflow as tf from tensorflow.keras.optimizers import Adam from tensorflow.keras.initializers import RandomNormal from tensorflow.keras.layers import Dense from tensorflow.keras.models import Sequential Create a dense neural network with Spectral channels as input to infer LAI values. X_train , X_val , y_train , y_val = train_test_split ( X_spec , y_lai , train_size = 0.8 , test_size = 0.2 , random_state = 0 ) Create the model # Hyperparameters batch_size = 16 epochs = 150 optimizer = Adam ( lr = 0.01 ) weight_init = RandomNormal () modelLoss = tf . keras . losses . MeanSquaredError () metricLoss = tf . keras . metrics . MeanSquaredError () val_mse_loss = tf . keras . metrics . MeanSquaredError () def get_net ( weight_init ): net = Sequential () net . add ( Dense ( 16 , kernel_initializer = weight_init , activation = 'relu' , input_dim = 10 )) net . add ( Dense ( 16 , kernel_initializer = weight_init , activation = 'relu' )) #kernel_initializer=weight_init net . add ( Dense ( 8 , kernel_initializer = weight_init , activation = 'relu' )) net . add ( Dense ( 1 )) return net Start the training process # Load the defined DNN model model = get_net ( weight_init ) # Initialize control training values train_loss_results = [] validation_loss_results = [] stop = False last_improvement = 0 last_improvement_total = 0 epoch = 0 best_loss = 100 # Calculate batches for training and validation bat_per_epoch = math . floor ( len ( X_train ) / batch_size ) bat_per_epoch_val = math . floor ( len ( X_val ) / batch_size ) # Training loop while epoch < epochs and stop == False : #for epoch in range(epochs): #print(f'Epoch: {epoch}/{epochs}') epoch_train_loss_avg = tf . keras . metrics . Mean () epoch_val_loss_avg = tf . keras . metrics . Mean () # Run train batch loop for i in range ( 1 , bat_per_epoch ): n = i * batch_size X_batch = X_train [ n : n + batch_size ] #X_train[ids_train[n:n+batch_size]] y_batch = y_train [ n : n + batch_size ] #y_train.take(ids_train[n:n+batch_size]) with tf . GradientTape () as tape : # Make prediction pred_y = model ( X_batch ) # Calculate loss train_loss = modelLoss ( tf . expand_dims ( y_batch . values , axis = 1 ), pred_y ) # Calculate gradients model_gradients = tape . gradient ( train_loss , model . trainable_variables ) # Update model optimizer . apply_gradients ( zip ( model_gradients , model . trainable_variables )) # Keep history of loss values epoch_train_loss_avg . update_state ( train_loss ) #End training batch train_loss_results . append ( epoch_train_loss_avg . result ()) # Run a validation loop at the end of each training epoch for i in range ( bat_per_epoch_val ): n = i * batch_size X_batch = X_val [ n : n + batch_size ] #X_val[ids_val[n:n+batch_size]] y_batch = y_val [ n : n + batch_size ] #y_val.take(ids_val[n:n+batch_size]) # Make prediction val_pred = model ( X_batch ) val_loss = val_mse_loss ( tf . expand_dims ( y_batch . values , axis = 1 ), val_pred ) # Keep history of validation loss values epoch_val_loss_avg . update_state ( val_loss ) # Read out training results #(f'Validation loss: {val_loss}') #End validation batch validation_loss_results . append ( epoch_val_loss_avg . result ()) print ( f 'Epoch: { epoch } / { epochs } Loss: { epoch_train_loss_avg . result () } , Val_loss: { epoch_val_loss_avg . result () } ' ) # Custom callback functions if epoch_val_loss_avg . result () < best_loss : best_loss = epoch_val_loss_avg . result () last_improvement = 0 else : last_improvement += 1 # Reduce learning rate if validation loss does not decrease for 10 epochs if last_improvement > 10 : lr = optimizer . lr . numpy () optimizer . lr . assign ( lr / 10 ) print ( f 'No improvement, reduce learning rate { lr / 10 } ' ) last_improvement_total = last_improvement last_improvement = 0 # Stop training if validation loss does not decrease for 20 epochs if last_improvement_total > 20 : print ( f 'No improvement after 20 epochs. Stop training' ) stop = True epoch += 1 To run the training faster it can be wrapped into a @tf.function as: @tf.function def train_model(x, y): with tf.GradientTape() as tape: y_pred = model(x) loss = loss_fn(y, y_pred) gradients = tape.gradient(loss, model.trainable_weights) optimizer.apply_gradients(zip(gradients, model.trainable_weights)) train_loss.update_state(loss)","title":"Intro"},{"location":"code/info/#code","text":"","title":"CODE"},{"location":"code/info/#jax","text":"Autograd and XLA toguether for high-performance machine learning research. With Autograd Automatically differentiate native Python and NumPy functions. grad = Supports reverse mode differentiation (backpropagation) With XLA Compile and run NumPy programs on GPUs and TPUs. Compilation under the hood by default.","title":"JAX"},{"location":"code/info/#tensorflow","text":"tf.GradientTape(): For automatic differentiation computing the gradient of a computation with respect to its input variables. \"Tape\" records all the operations executed. Import the necessary packages import tensorflow as tf from tensorflow.keras.optimizers import Adam from tensorflow.keras.initializers import RandomNormal from tensorflow.keras.layers import Dense from tensorflow.keras.models import Sequential Create a dense neural network with Spectral channels as input to infer LAI values. X_train , X_val , y_train , y_val = train_test_split ( X_spec , y_lai , train_size = 0.8 , test_size = 0.2 , random_state = 0 ) Create the model # Hyperparameters batch_size = 16 epochs = 150 optimizer = Adam ( lr = 0.01 ) weight_init = RandomNormal () modelLoss = tf . keras . losses . MeanSquaredError () metricLoss = tf . keras . metrics . MeanSquaredError () val_mse_loss = tf . keras . metrics . MeanSquaredError () def get_net ( weight_init ): net = Sequential () net . add ( Dense ( 16 , kernel_initializer = weight_init , activation = 'relu' , input_dim = 10 )) net . add ( Dense ( 16 , kernel_initializer = weight_init , activation = 'relu' )) #kernel_initializer=weight_init net . add ( Dense ( 8 , kernel_initializer = weight_init , activation = 'relu' )) net . add ( Dense ( 1 )) return net Start the training process # Load the defined DNN model model = get_net ( weight_init ) # Initialize control training values train_loss_results = [] validation_loss_results = [] stop = False last_improvement = 0 last_improvement_total = 0 epoch = 0 best_loss = 100 # Calculate batches for training and validation bat_per_epoch = math . floor ( len ( X_train ) / batch_size ) bat_per_epoch_val = math . floor ( len ( X_val ) / batch_size ) # Training loop while epoch < epochs and stop == False : #for epoch in range(epochs): #print(f'Epoch: {epoch}/{epochs}') epoch_train_loss_avg = tf . keras . metrics . Mean () epoch_val_loss_avg = tf . keras . metrics . Mean () # Run train batch loop for i in range ( 1 , bat_per_epoch ): n = i * batch_size X_batch = X_train [ n : n + batch_size ] #X_train[ids_train[n:n+batch_size]] y_batch = y_train [ n : n + batch_size ] #y_train.take(ids_train[n:n+batch_size]) with tf . GradientTape () as tape : # Make prediction pred_y = model ( X_batch ) # Calculate loss train_loss = modelLoss ( tf . expand_dims ( y_batch . values , axis = 1 ), pred_y ) # Calculate gradients model_gradients = tape . gradient ( train_loss , model . trainable_variables ) # Update model optimizer . apply_gradients ( zip ( model_gradients , model . trainable_variables )) # Keep history of loss values epoch_train_loss_avg . update_state ( train_loss ) #End training batch train_loss_results . append ( epoch_train_loss_avg . result ()) # Run a validation loop at the end of each training epoch for i in range ( bat_per_epoch_val ): n = i * batch_size X_batch = X_val [ n : n + batch_size ] #X_val[ids_val[n:n+batch_size]] y_batch = y_val [ n : n + batch_size ] #y_val.take(ids_val[n:n+batch_size]) # Make prediction val_pred = model ( X_batch ) val_loss = val_mse_loss ( tf . expand_dims ( y_batch . values , axis = 1 ), val_pred ) # Keep history of validation loss values epoch_val_loss_avg . update_state ( val_loss ) # Read out training results #(f'Validation loss: {val_loss}') #End validation batch validation_loss_results . append ( epoch_val_loss_avg . result ()) print ( f 'Epoch: { epoch } / { epochs } Loss: { epoch_train_loss_avg . result () } , Val_loss: { epoch_val_loss_avg . result () } ' ) # Custom callback functions if epoch_val_loss_avg . result () < best_loss : best_loss = epoch_val_loss_avg . result () last_improvement = 0 else : last_improvement += 1 # Reduce learning rate if validation loss does not decrease for 10 epochs if last_improvement > 10 : lr = optimizer . lr . numpy () optimizer . lr . assign ( lr / 10 ) print ( f 'No improvement, reduce learning rate { lr / 10 } ' ) last_improvement_total = last_improvement last_improvement = 0 # Stop training if validation loss does not decrease for 20 epochs if last_improvement_total > 20 : print ( f 'No improvement after 20 epochs. Stop training' ) stop = True epoch += 1 To run the training faster it can be wrapped into a @tf.function as: @tf.function def train_model(x, y): with tf.GradientTape() as tape: y_pred = model(x) loss = loss_fn(y, y_pred) gradients = tape.gradient(loss, model.trainable_weights) optimizer.apply_gradients(zip(gradients, model.trainable_weights)) train_loss.update_state(loss)","title":"Tensorflow"},{"location":"code/python/","text":"General concepts of python Here I want to write common tips that help me during my programming. Check current path import os print ( os . getcwd ()) Change current working dir import os os . chdir ( * new_path )","title":"Python"},{"location":"code/python/#general-concepts-of-python","text":"Here I want to write common tips that help me during my programming.","title":"General concepts of python"},{"location":"code/python/#check-current-path","text":"import os print ( os . getcwd ())","title":"Check current path"},{"location":"code/python/#change-current-working-dir","text":"import os os . chdir ( * new_path )","title":"Change current working dir"},{"location":"code/tf_datasets/","text":"Datasets tf.data.Dataset allows to iterate over the dataset in a streaming fashion, so the full dataset does not need to fit into memory. tf.data.Dataset.zip tf.data.Dataset.from_tensor_slices : to create the dataset from a python list","title":"Datasets"},{"location":"code/tf_datasets/#datasets","text":"tf.data.Dataset allows to iterate over the dataset in a streaming fashion, so the full dataset does not need to fit into memory. tf.data.Dataset.zip tf.data.Dataset.from_tensor_slices : to create the dataset from a python list","title":"Datasets"},{"location":"earthscience/databases/","text":"7 FREE sites for downloading satellite images USGS Landviewer Copernicus - \"Sentinels Scientific Datahub\" - ESA Sentinel hub NASA earthData search - NASA EOSDIS Remote PIXEL INPE image catalog IN-SITU databases NEON (National Ecological Observatory Network) Data from 81 field sites across the united states (47 terrestial + 34 aquatic) Products USGS Every one to two days MODIS Aqua and Terra spacecraft views the entire surface of the Earth. In here there is a table with all the MODIS (Moderate Resolution Imaging Spectroradiometer) products available. For example we can filter LAI and FPAR products. The result MCD15A[3,2]H is a collection of combined MODIS, Terra MODIS or Aqua MODIS. It has a spatial resolution of 500m and a Multi-day temporal resolution. Copernicus global land service Product: Leaf Area Index (LAI) Sensor: PROVA-V Spatial information: 300m - 1km Temporal coverage: Jan 2014 - present, 1999 - present url: portal output files: GeoTIFF if the product is clipped, otherwise is NETCDF Example of plotting LAI values from a downloaded product. from netCDF4 import Dataset import numpy as np import matplotlib.pyplot as plt from mpl_toolkits.basemap import Basemap data = Dataset ( r 'C:\\IRENE\\IPL WORK\\copernicus data\\c_gls_LAI-RT0_202004200000_GLOBE_PROBAV_V2.0.1.nc' ) #get all the data lats = data . variables [ 'lat' ][:] lons = data . variables [ 'lon' ][:] times = data . variables [ 'time' ][:] # MAP coordinates for SPAIN using ESPG reference mp = Basemap ( llcrnrlat = 34 , urcrnrlat = 45 , llcrnrlon =- 10 , urcrnrlon = 4 , resolution = 'i' , epsg = 4326 ) lat_x = np . where ( lats > 34 ) lat_y = np . where ( lats < 45 ) lon_x = np . where ( lons >- 10 ) lon_y = np . where ( lons < 4 ) long , lat = np . meshgrid ( lons [ lon_x [ 0 ][ 0 ]: lon_y [ 0 ][ - 1 ]], lats [ lat_y [ 0 ][ 0 ]: lat_x [ 0 ][ - 1 ]]) x , y = mp ( long , lat ) cmap = plt . cm . Greens c_scheme = mp . pcolor ( x , y , np . squeeze ( lais [ 0 , lat_y [ 0 ][ 0 ]: lat_x [ 0 ][ - 1 ], lon_x [ 0 ][ 0 ]: lon_y [ 0 ][ - 1 ]]), cmap = cmap ) #, mp . drawcoastlines () mp . drawstates () mp . drawcountries () cbar = mp . colorbar ( c_scheme , location = 'right' , pad = '10%' ) plt . title ( 'LAI values' ) plt . show ()","title":"Databases"},{"location":"earthscience/databases/#7-free-sites-for-downloading-satellite-images","text":"USGS Landviewer Copernicus - \"Sentinels Scientific Datahub\" - ESA Sentinel hub NASA earthData search - NASA EOSDIS Remote PIXEL INPE image catalog","title":"7 FREE sites for downloading satellite images"},{"location":"earthscience/databases/#in-situ-databases","text":"NEON (National Ecological Observatory Network) Data from 81 field sites across the united states (47 terrestial + 34 aquatic)","title":"IN-SITU databases"},{"location":"earthscience/databases/#products","text":"","title":"Products"},{"location":"earthscience/databases/#usgs","text":"Every one to two days MODIS Aqua and Terra spacecraft views the entire surface of the Earth. In here there is a table with all the MODIS (Moderate Resolution Imaging Spectroradiometer) products available. For example we can filter LAI and FPAR products. The result MCD15A[3,2]H is a collection of combined MODIS, Terra MODIS or Aqua MODIS. It has a spatial resolution of 500m and a Multi-day temporal resolution.","title":"USGS"},{"location":"earthscience/databases/#copernicus-global-land-service","text":"Product: Leaf Area Index (LAI) Sensor: PROVA-V Spatial information: 300m - 1km Temporal coverage: Jan 2014 - present, 1999 - present url: portal output files: GeoTIFF if the product is clipped, otherwise is NETCDF Example of plotting LAI values from a downloaded product. from netCDF4 import Dataset import numpy as np import matplotlib.pyplot as plt from mpl_toolkits.basemap import Basemap data = Dataset ( r 'C:\\IRENE\\IPL WORK\\copernicus data\\c_gls_LAI-RT0_202004200000_GLOBE_PROBAV_V2.0.1.nc' ) #get all the data lats = data . variables [ 'lat' ][:] lons = data . variables [ 'lon' ][:] times = data . variables [ 'time' ][:] # MAP coordinates for SPAIN using ESPG reference mp = Basemap ( llcrnrlat = 34 , urcrnrlat = 45 , llcrnrlon =- 10 , urcrnrlon = 4 , resolution = 'i' , epsg = 4326 ) lat_x = np . where ( lats > 34 ) lat_y = np . where ( lats < 45 ) lon_x = np . where ( lons >- 10 ) lon_y = np . where ( lons < 4 ) long , lat = np . meshgrid ( lons [ lon_x [ 0 ][ 0 ]: lon_y [ 0 ][ - 1 ]], lats [ lat_y [ 0 ][ 0 ]: lat_x [ 0 ][ - 1 ]]) x , y = mp ( long , lat ) cmap = plt . cm . Greens c_scheme = mp . pcolor ( x , y , np . squeeze ( lais [ 0 , lat_y [ 0 ][ 0 ]: lat_x [ 0 ][ - 1 ], lon_x [ 0 ][ 0 ]: lon_y [ 0 ][ - 1 ]]), cmap = cmap ) #, mp . drawcoastlines () mp . drawstates () mp . drawcountries () cbar = mp . colorbar ( c_scheme , location = 'right' , pad = '10%' ) plt . title ( 'LAI values' ) plt . show ()","title":"Copernicus global land service"},{"location":"earthscience/info/","text":"Earth Science Concepts related to Earth Science. NDVI : Normalized Difference Vegetation Index GPP : Gross Primary Productivity NPP : Net Primary Productivity APAR : Absorbed Photosynthetically Active Radiation FPAR : Fractional PAR FAPAR : Fraction of Absorbed PAR MODIS : Moderate Resolution Imaging Spectroradiometer LUE : Light Use Efficiency VPD : Vapor Preassure Deficit LE : Latent heat flux ET : EvapoTranspiration LAI : Leaf Area Index FOV : Field Of View TOA : Top Of Atmosphere ETM : Enhanced Thematic Mapper OLI : Operational Land Imager LaSRC : Landsat Surface Reflectance Code LEDAPS : Landsat Ecosystem Disturbance Adaptive Processing System","title":"Info"},{"location":"earthscience/info/#earth-science","text":"Concepts related to Earth Science. NDVI : Normalized Difference Vegetation Index GPP : Gross Primary Productivity NPP : Net Primary Productivity APAR : Absorbed Photosynthetically Active Radiation FPAR : Fractional PAR FAPAR : Fraction of Absorbed PAR MODIS : Moderate Resolution Imaging Spectroradiometer LUE : Light Use Efficiency VPD : Vapor Preassure Deficit LE : Latent heat flux ET : EvapoTranspiration LAI : Leaf Area Index FOV : Field Of View TOA : Top Of Atmosphere ETM : Enhanced Thematic Mapper OLI : Operational Land Imager LaSRC : Landsat Surface Reflectance Code LEDAPS : Landsat Ecosystem Disturbance Adaptive Processing System","title":"Earth Science"},{"location":"earthscience/multispectral/","text":"Multispectral Remote Sensing Data GIS Standard of encoding Geographical Information into a computer file. File formats Name properties extension netCDF (Network Common Data Form) File format with climate and Forecast (CF) metadata for earth science data. Binary storage in open format with optional compression. .nc GeoTIFF TIFF format which includes GIS compatible georeferencing systems. Byte data [0, 255] and colour scale. .tif / .tiff TIFF (Tagged Image File Format) Computer file format for storing raster graphics images. .tif / .tiff Shapefile Standard for representing geospatial vector data. Describes geometries as points, polylines or polygons. .shp Data structures Xarray Default package for handling spatial-temporal-variable datasets. In the format (latitude x longitude x time x variable) GeoPandas To store data from shapefiles. Raster Data stored as a grid of values which are rendered on a map as pixels. Each pixel value represents an area on the Earth's surface. Each cell \u2192 pixel \u2192 area on the ground Resolution \u2192 area that each pixel represents on the ground. ** Calculate NDVI from Landsat crop image ** Import the necessary packages import rasterio Load data imagePath = 'Landsat_collect/LC080340322016072301T1-SC20180214145802/crop/' imageFiles = glob . glob ( imagePath + '*_band*.tif' ) band4 = rasterio . open ( imageFiles [ 3 ]) #red band5 = rasterio . open ( imageFiles [ 4 ]) #nir Generate nir and red objects as arrays in float64 format nir = band5 . read ( 1 ) . astype ( 'float64' ) red = band4 . read ( 1 ) . astype ( 'float64' ) NDVI calculation, empty cells or nodata cells are reported as 0 ndvi = np . where ( ( nir + red ) == 0. , 0 , ( nir - red ) / ( nir + red ) ) Export ndvi image ndviImage = rasterio . open ( 'ndviImage.tiff' , 'w' , driver = 'Gtiff' , width = band4 . width , height = band4 . height , count = 1 , crs = band4 . crs , transform = band4 . transform , dtype = 'float64' ) ndviImage . write ( ndvi , 1 ) ndviImage . close () ENVI Image Files Flat-binary raster file with an ASCII header file. The data is stored as a binary stream of bytes with the following formats: Band Sequential ( BSQ ): each line is followed by the next line in the same spectral band. Band Interleaved by Pixel ( BIP ): Stores the first pixel for all bands in sequential order. Band Interleaved by Line ( BIL ): Stores the first line of the first band. Projection EPSG code = standard to name projections using a numerical code Pan-sharpening Some characteristics of some of the most used sensors Sensor Spatial resolution Temporal resolution Spectral resolution Landsat TM 30 m 16 days 7 bands MODIS 250 - 100 m 1 day 36 bands Pansharpening is a process of merging high-resolution panchromatic and lower resolution multispectral imagery to create a single high-resolution color image. Radiance to reflectance Radiance is the variable directly measured by temote sensing instruments. It is how much light the instrument 'sees' from the object being observed. Depends on the illumination, the orientation and position of the target and the path of the light through the atmosphere. Reflectance is the ratio of the amount of light leaving a a target to the amount of light striking the target. It is a property of the material being observed. Spectral response functions (SRFs) Spectral response describes the sensitivity of the photosensor to optical radiation of different wavelengths. Tutorials Earth Lab: Multispectral remote sensing data in python Differential calculus: python colab","title":"Multispectral"},{"location":"earthscience/multispectral/#multispectral-remote-sensing-data","text":"","title":"Multispectral Remote Sensing Data"},{"location":"earthscience/multispectral/#gis","text":"Standard of encoding Geographical Information into a computer file.","title":"GIS"},{"location":"earthscience/multispectral/#file-formats","text":"Name properties extension netCDF (Network Common Data Form) File format with climate and Forecast (CF) metadata for earth science data. Binary storage in open format with optional compression. .nc GeoTIFF TIFF format which includes GIS compatible georeferencing systems. Byte data [0, 255] and colour scale. .tif / .tiff TIFF (Tagged Image File Format) Computer file format for storing raster graphics images. .tif / .tiff Shapefile Standard for representing geospatial vector data. Describes geometries as points, polylines or polygons. .shp","title":"File formats"},{"location":"earthscience/multispectral/#data-structures","text":"","title":"Data structures"},{"location":"earthscience/multispectral/#xarray","text":"Default package for handling spatial-temporal-variable datasets. In the format (latitude x longitude x time x variable)","title":"Xarray"},{"location":"earthscience/multispectral/#geopandas","text":"To store data from shapefiles.","title":"GeoPandas"},{"location":"earthscience/multispectral/#raster","text":"Data stored as a grid of values which are rendered on a map as pixels. Each pixel value represents an area on the Earth's surface. Each cell \u2192 pixel \u2192 area on the ground Resolution \u2192 area that each pixel represents on the ground. ** Calculate NDVI from Landsat crop image ** Import the necessary packages import rasterio Load data imagePath = 'Landsat_collect/LC080340322016072301T1-SC20180214145802/crop/' imageFiles = glob . glob ( imagePath + '*_band*.tif' ) band4 = rasterio . open ( imageFiles [ 3 ]) #red band5 = rasterio . open ( imageFiles [ 4 ]) #nir Generate nir and red objects as arrays in float64 format nir = band5 . read ( 1 ) . astype ( 'float64' ) red = band4 . read ( 1 ) . astype ( 'float64' ) NDVI calculation, empty cells or nodata cells are reported as 0 ndvi = np . where ( ( nir + red ) == 0. , 0 , ( nir - red ) / ( nir + red ) ) Export ndvi image ndviImage = rasterio . open ( 'ndviImage.tiff' , 'w' , driver = 'Gtiff' , width = band4 . width , height = band4 . height , count = 1 , crs = band4 . crs , transform = band4 . transform , dtype = 'float64' ) ndviImage . write ( ndvi , 1 ) ndviImage . close ()","title":"Raster"},{"location":"earthscience/multispectral/#envi-image-files","text":"Flat-binary raster file with an ASCII header file. The data is stored as a binary stream of bytes with the following formats: Band Sequential ( BSQ ): each line is followed by the next line in the same spectral band. Band Interleaved by Pixel ( BIP ): Stores the first pixel for all bands in sequential order. Band Interleaved by Line ( BIL ): Stores the first line of the first band.","title":"ENVI Image Files"},{"location":"earthscience/multispectral/#projection","text":"EPSG code = standard to name projections using a numerical code","title":"Projection"},{"location":"earthscience/multispectral/#pan-sharpening","text":"Some characteristics of some of the most used sensors Sensor Spatial resolution Temporal resolution Spectral resolution Landsat TM 30 m 16 days 7 bands MODIS 250 - 100 m 1 day 36 bands Pansharpening is a process of merging high-resolution panchromatic and lower resolution multispectral imagery to create a single high-resolution color image.","title":"Pan-sharpening"},{"location":"earthscience/multispectral/#radiance-to-reflectance","text":"Radiance is the variable directly measured by temote sensing instruments. It is how much light the instrument 'sees' from the object being observed. Depends on the illumination, the orientation and position of the target and the path of the light through the atmosphere. Reflectance is the ratio of the amount of light leaving a a target to the amount of light striking the target. It is a property of the material being observed.","title":"Radiance to reflectance"},{"location":"earthscience/multispectral/#spectral-response-functions-srfs","text":"Spectral response describes the sensitivity of the photosensor to optical radiation of different wavelengths.","title":"Spectral response functions (SRFs)"},{"location":"earthscience/multispectral/#tutorials","text":"Earth Lab: Multispectral remote sensing data in python Differential calculus: python colab","title":"Tutorials"},{"location":"error/info/","text":"Error propagation Equation of the error propagation law C_y = F_X C_X F_X^T C_y = F_X C_X F_X^T Applications: error propagation in model-based vision, Kalman filtering, reliability or probabilistic systems analysis. Error propagation is the problem of finding the distribution of a function of random variables. Given a mathematical model Y = f(X) Y = f(X) , if f(\u00b7) f(\u00b7) is non-linear we try to approximate the probability distribution function ( p_Y(y) p_Y(y) ) of Y Y by the propagation of the first two statistical moments: mean \\mu_Y \\mu_Y variance \\sigma_Y^2 \\sigma_Y^2 (the second central moment) Remember Standard deviation \\sigma \\sigma = distance between the most probable value ( \\mu \\mu ) and the curve's turning points. Property of normal distribution: Gaussian stays Gaussian under linear transformations. By using first-order Taylor series expansion we obtain a linear relationship in order to determine the parameters \\mu_Y \\mu_Y and \\sigma_Y \\sigma_Y , which approximate the unknown truth, by a normal distribution for p_Y(y) p_Y(y) . Notation x^* x^* guess of the expected value. Considering multi-input and multi-output system we apply first order Taylor series expansion and then reformulate the output equations to obtain their matrix form. Jacobian F_X F_X is the transpose of the gradient of \\mathbb{f}(X) \\mathbb{f}(X) C_X C_X is the input covarience matrix, which contains all variances and covariances of the input random variables. The input uncertainty C_X C_X is propagated through the system f(\u00b7) f(\u00b7) and approximatively mapped to the output C_Y C_Y . Taylor Series Used to approximate functions. Obtain derivative information at a point to output information near that point. P(x) = f(a) + \\frac{df}{dx}(a) \\frac{(x-a)^1}{1!} + \\frac{d^2f}{dx^2}(a) \\frac{(x-a)^2}{2!} + \\frac{d^3f}{dx^3}(a) \\frac{(x-a)^3}{3!} + ... P(x) = f(a) + \\frac{df}{dx}(a) \\frac{(x-a)^1}{1!} + \\frac{d^2f}{dx^2}(a) \\frac{(x-a)^2}{2!} + \\frac{d^3f}{dx^3}(a) \\frac{(x-a)^3}{3!} + ... Example for e^x e^x in a = 0 a = 0 P(x) = 1 + 1 \\frac{x^1}{1!} + 1 \\frac{x^2}{2!} + 1 \\frac{x^3}{3!} + 1 \\frac{x^4}{4!}+ ... P(x) = 1 + 1 \\frac{x^1}{1!} + 1 \\frac{x^2}{2!} + 1 \\frac{x^3}{3!} + 1 \\frac{x^4}{4!}+ ... They can also be used to approximate the area of a function. Kalman Filter Powerful tool for combining information in the presence of uncertainty. Also known as linear quadratic estimation (LQE) Recursive algorithm, uses measurements over time which contain statistical noise (inaccuracies) and produces estimates of unknown variables by estimating a joint probability distribution over the variables for each timeframe. Documentation: Using non-linear Kalman filtering to estimate signals pdf An introduction to particle filters slides","title":"Intro"},{"location":"error/info/#error-propagation","text":"Equation of the error propagation law C_y = F_X C_X F_X^T C_y = F_X C_X F_X^T Applications: error propagation in model-based vision, Kalman filtering, reliability or probabilistic systems analysis. Error propagation is the problem of finding the distribution of a function of random variables. Given a mathematical model Y = f(X) Y = f(X) , if f(\u00b7) f(\u00b7) is non-linear we try to approximate the probability distribution function ( p_Y(y) p_Y(y) ) of Y Y by the propagation of the first two statistical moments: mean \\mu_Y \\mu_Y variance \\sigma_Y^2 \\sigma_Y^2 (the second central moment) Remember Standard deviation \\sigma \\sigma = distance between the most probable value ( \\mu \\mu ) and the curve's turning points. Property of normal distribution: Gaussian stays Gaussian under linear transformations. By using first-order Taylor series expansion we obtain a linear relationship in order to determine the parameters \\mu_Y \\mu_Y and \\sigma_Y \\sigma_Y , which approximate the unknown truth, by a normal distribution for p_Y(y) p_Y(y) . Notation x^* x^* guess of the expected value. Considering multi-input and multi-output system we apply first order Taylor series expansion and then reformulate the output equations to obtain their matrix form. Jacobian F_X F_X is the transpose of the gradient of \\mathbb{f}(X) \\mathbb{f}(X) C_X C_X is the input covarience matrix, which contains all variances and covariances of the input random variables. The input uncertainty C_X C_X is propagated through the system f(\u00b7) f(\u00b7) and approximatively mapped to the output C_Y C_Y .","title":"Error propagation"},{"location":"error/info/#taylor-series","text":"Used to approximate functions. Obtain derivative information at a point to output information near that point. P(x) = f(a) + \\frac{df}{dx}(a) \\frac{(x-a)^1}{1!} + \\frac{d^2f}{dx^2}(a) \\frac{(x-a)^2}{2!} + \\frac{d^3f}{dx^3}(a) \\frac{(x-a)^3}{3!} + ... P(x) = f(a) + \\frac{df}{dx}(a) \\frac{(x-a)^1}{1!} + \\frac{d^2f}{dx^2}(a) \\frac{(x-a)^2}{2!} + \\frac{d^3f}{dx^3}(a) \\frac{(x-a)^3}{3!} + ... Example for e^x e^x in a = 0 a = 0 P(x) = 1 + 1 \\frac{x^1}{1!} + 1 \\frac{x^2}{2!} + 1 \\frac{x^3}{3!} + 1 \\frac{x^4}{4!}+ ... P(x) = 1 + 1 \\frac{x^1}{1!} + 1 \\frac{x^2}{2!} + 1 \\frac{x^3}{3!} + 1 \\frac{x^4}{4!}+ ... They can also be used to approximate the area of a function.","title":"Taylor Series"},{"location":"error/info/#kalman-filter","text":"Powerful tool for combining information in the presence of uncertainty. Also known as linear quadratic estimation (LQE) Recursive algorithm, uses measurements over time which contain statistical noise (inaccuracies) and produces estimates of unknown variables by estimating a joint probability distribution over the variables for each timeframe. Documentation: Using non-linear Kalman filtering to estimate signals pdf An introduction to particle filters slides","title":"Kalman Filter"},{"location":"error/losses/","text":"Loss Functions Typical loss functions for regression MAE Mean Absolute Error or L_1 L_1 loss MAE = \\frac{ \\sum_{i=1}^n |y_i - \\hat{y}_i| }{n} MAE = \\frac{ \\sum_{i=1}^n |y_i - \\hat{y}_i| }{n} MSE Mean Square Error, quadratic loss or L_2 L_2 loss MSE = \\frac{ \\sum_{i=1}^n (y_i - \\hat{y}_i)^2 }{n} MSE = \\frac{ \\sum_{i=1}^n (y_i - \\hat{y}_i)^2 }{n} MSLE Mean Square Logarithmic Error MSLE = \\frac{ \\sum_{i=1}^n (\\log(y_i+1) - \\log(\\hat{y}_i+1))^2 }{n}, MSLE = \\frac{ \\sum_{i=1}^n (\\log(y_i+1) - \\log(\\hat{y}_i+1))^2 }{n}, where +1 +1 is for mathematical convenience when applying backpropagation Loss functions for quantile regression Pinball loss Modification of the MAE loss and allows conditional quantile regression. It is used to evaluate the accuracy of a quantile forecast. \\begin{split} L_\\tau(y, \\hat{y}) &= (y-\\hat{y})\\tau &\\quad if \\quad y - \\hat{y}\\geq 0\\\\ &= (\\hat{y}-y)(1-\\tau) &\\quad else. \\end{split} \\begin{split} L_\\tau(y, \\hat{y}) &= (y-\\hat{y})\\tau &\\quad if \\quad y - \\hat{y}\\geq 0\\\\ &= (\\hat{y}-y)(1-\\tau) &\\quad else. \\end{split} Where \\tau \\tau is the target quantile, y y the real value and \\hat{y} \\hat{y} the quantile forecast. The lower the pinball loss, the higher the accuracy of the quantile estimation.","title":"Losses"},{"location":"error/losses/#loss-functions","text":"","title":"Loss Functions"},{"location":"error/losses/#typical-loss-functions-for-regression","text":"","title":"Typical loss functions for regression"},{"location":"error/losses/#mae","text":"Mean Absolute Error or L_1 L_1 loss MAE = \\frac{ \\sum_{i=1}^n |y_i - \\hat{y}_i| }{n} MAE = \\frac{ \\sum_{i=1}^n |y_i - \\hat{y}_i| }{n}","title":"MAE"},{"location":"error/losses/#mse","text":"Mean Square Error, quadratic loss or L_2 L_2 loss MSE = \\frac{ \\sum_{i=1}^n (y_i - \\hat{y}_i)^2 }{n} MSE = \\frac{ \\sum_{i=1}^n (y_i - \\hat{y}_i)^2 }{n}","title":"MSE"},{"location":"error/losses/#msle","text":"Mean Square Logarithmic Error MSLE = \\frac{ \\sum_{i=1}^n (\\log(y_i+1) - \\log(\\hat{y}_i+1))^2 }{n}, MSLE = \\frac{ \\sum_{i=1}^n (\\log(y_i+1) - \\log(\\hat{y}_i+1))^2 }{n}, where +1 +1 is for mathematical convenience when applying backpropagation","title":"MSLE"},{"location":"error/losses/#loss-functions-for-quantile-regression","text":"","title":"Loss functions for quantile regression"},{"location":"error/losses/#pinball-loss","text":"Modification of the MAE loss and allows conditional quantile regression. It is used to evaluate the accuracy of a quantile forecast. \\begin{split} L_\\tau(y, \\hat{y}) &= (y-\\hat{y})\\tau &\\quad if \\quad y - \\hat{y}\\geq 0\\\\ &= (\\hat{y}-y)(1-\\tau) &\\quad else. \\end{split} \\begin{split} L_\\tau(y, \\hat{y}) &= (y-\\hat{y})\\tau &\\quad if \\quad y - \\hat{y}\\geq 0\\\\ &= (\\hat{y}-y)(1-\\tau) &\\quad else. \\end{split} Where \\tau \\tau is the target quantile, y y the real value and \\hat{y} \\hat{y} the quantile forecast. The lower the pinball loss, the higher the accuracy of the quantile estimation.","title":"Pinball loss"},{"location":"error/quantile/","text":"Quantile regression Confidence intervals are built with quantile regression conditional quantiles \u2192 the median (0.5 quantile) scikit-learn Gradient boosting regressor to do quantile regression. Each quantile needs its own regressor.","title":"Quantile"},{"location":"error/quantile/#quantile-regression","text":"Confidence intervals are built with quantile regression conditional quantiles \u2192 the median (0.5 quantile) scikit-learn Gradient boosting regressor to do quantile regression. Each quantile needs its own regressor.","title":"Quantile regression"},{"location":"error/uncertainty/","text":"Random or Statistical uncertainties Come from fluctuations in a measurament. Since random fluctuations average to zero, we have to average a large number of measuraments. They are described by the normal distribution (Gaussian, \"bell curve\"), we calculate the standard deviation in order to descibe the width of the distribution. TYPES : Epistemic : systematic things we don't know because of a lack of data or experience. Uncertainty in the model. It is inversely proportional to the density of training examples, reduced by collecting data in the low density region. Aleatoric : statistical things that are simply unknown. Uncertainty in the data. It describes the varience of the conditional distribution of our target variable given our features. Confidence Interval (CI): shows what the uncertainty is within a certain statistic. It is IMPORTANT to be aware of uncertainty in prediction. Uncertainty quantification is one step towards model interpretability. Heteroscedasticity From Hetero different and skedasis dispersion . When the variability of the random disturbance is different across elements of the vector. Bayesian statistics Are statistical methods that estimate the probability that a hypothesis is true, modifying and updating the probability as more studies are conducted and more information becomes available. In Bayesian methods the posterior distribution is approximated: by variational distribution, like in neural networks. by Montecarlo methods, like in probabilistic graphical models. Bayesian Deep Learning (BDL) Bayesian Neural Networks (BNN) Gaussian process: a network with infinitely many weights with a distribution on each weight. BNN: a network with finitely many weights with a distribution on each weight. Learn parameters of a random variable which is use to sample the weights during forward propagation. Those parameters are the mean and variance of a distribution, for example a Gaussian. Steps: Initialize with random parameters, 0 mean and unit variance for example. For each batch Sample weights according to the distribution Forward pass Backpropagate the loss to the parameters of the distribution that generated the weights. Make the NN Bayesian Dropout Reduce overfitting by randomly setting activation to zeros in a given layer. During training: Dropout is activated During inference: Dropout is deactivated in order to use all the neurons. It is like using Bernoullis random variable to sample the weights. If the Dropout is on during inference and sample several models, which is called Monte Carlo Dropout (or MC Dropout). Measures of uncertainty In classification: Predictive entropy Information gained about the model parameters Variation ratios Random acquisition BALD (Bayesian Active Learning by Disagreement)","title":"Uncertainty"},{"location":"error/uncertainty/#random-or-statistical-uncertainties","text":"Come from fluctuations in a measurament. Since random fluctuations average to zero, we have to average a large number of measuraments. They are described by the normal distribution (Gaussian, \"bell curve\"), we calculate the standard deviation in order to descibe the width of the distribution. TYPES : Epistemic : systematic things we don't know because of a lack of data or experience. Uncertainty in the model. It is inversely proportional to the density of training examples, reduced by collecting data in the low density region. Aleatoric : statistical things that are simply unknown. Uncertainty in the data. It describes the varience of the conditional distribution of our target variable given our features. Confidence Interval (CI): shows what the uncertainty is within a certain statistic. It is IMPORTANT to be aware of uncertainty in prediction. Uncertainty quantification is one step towards model interpretability.","title":"Random or Statistical uncertainties"},{"location":"error/uncertainty/#heteroscedasticity","text":"From Hetero different and skedasis dispersion . When the variability of the random disturbance is different across elements of the vector.","title":"Heteroscedasticity"},{"location":"error/uncertainty/#bayesian-statistics","text":"Are statistical methods that estimate the probability that a hypothesis is true, modifying and updating the probability as more studies are conducted and more information becomes available. In Bayesian methods the posterior distribution is approximated: by variational distribution, like in neural networks. by Montecarlo methods, like in probabilistic graphical models. Bayesian Deep Learning (BDL) Bayesian Neural Networks (BNN) Gaussian process: a network with infinitely many weights with a distribution on each weight. BNN: a network with finitely many weights with a distribution on each weight. Learn parameters of a random variable which is use to sample the weights during forward propagation. Those parameters are the mean and variance of a distribution, for example a Gaussian. Steps: Initialize with random parameters, 0 mean and unit variance for example. For each batch Sample weights according to the distribution Forward pass Backpropagate the loss to the parameters of the distribution that generated the weights. Make the NN Bayesian","title":"Bayesian statistics"},{"location":"error/uncertainty/#dropout","text":"Reduce overfitting by randomly setting activation to zeros in a given layer. During training: Dropout is activated During inference: Dropout is deactivated in order to use all the neurons. It is like using Bernoullis random variable to sample the weights. If the Dropout is on during inference and sample several models, which is called Monte Carlo Dropout (or MC Dropout).","title":"Dropout"},{"location":"error/uncertainty/#measures-of-uncertainty","text":"In classification: Predictive entropy Information gained about the model parameters Variation ratios Random acquisition BALD (Bayesian Active Learning by Disagreement)","title":"Measures of uncertainty"},{"location":"hybrid/intro/","text":"Hybrid modelling Definition It combines the strengths of physical modelling (knowledge driven, physically interpretable extrapolation possible) and machine learning (data driven, less prior knowledge). Advantages: Adds prior knowledge Interpretable latent variables Objectives: Improving predictions Parametrization Forward solving partial differential equations Inverse modelling Discovering governing equations Methods: Physics-guide learning Physics-based loss: current approach Auxiliary task in multi-task learning Physics guide initialization (transfer learning) Physics-guide architecture Residual modelling Hybrid physics-ML models It can be related to data assimilation and Kalman filtering therefore to GP . Multi-task learning Multi-task loss function which can learn to balance various regression and classification losses. Benefit: It can improve accuracy over separately trained models. Improves generalisation by sharing domain information between complimentary tasks. Examples: Fine-tuning: here, different learning tasks are used as a pre-training step. Learn unsupervised features from various data sources with an auto-encoder. L_{total} = \\sum_i w_i L_i L_{total} = \\sum_i w_i L_i RTM (Radiative Transfer Models) Forward modelling: determine physical laws which govern complex phenomena. Inverse modelling: determine the underlying physical conditions which correspond to a given set of real obtained values. Prosail PROSPECT: leaf optical properties model SAIL: Canopy bidirectional reflectance model Inputs (14) Importants (9) non-importants (5) LAI Leaf chlorophyll Biomas ... ------------- ------------------------ -------------------- Ouputs Different wave lengths Ideas Update the weights of the model (neural network) based on how the similarity increase between the weight vector to the input.","title":"Intro"},{"location":"hybrid/intro/#hybrid-modelling","text":"Definition It combines the strengths of physical modelling (knowledge driven, physically interpretable extrapolation possible) and machine learning (data driven, less prior knowledge). Advantages: Adds prior knowledge Interpretable latent variables Objectives: Improving predictions Parametrization Forward solving partial differential equations Inverse modelling Discovering governing equations Methods: Physics-guide learning Physics-based loss: current approach Auxiliary task in multi-task learning Physics guide initialization (transfer learning) Physics-guide architecture Residual modelling Hybrid physics-ML models It can be related to data assimilation and Kalman filtering therefore to GP .","title":"Hybrid modelling"},{"location":"hybrid/intro/#multi-task-learning","text":"Multi-task loss function which can learn to balance various regression and classification losses. Benefit: It can improve accuracy over separately trained models. Improves generalisation by sharing domain information between complimentary tasks. Examples: Fine-tuning: here, different learning tasks are used as a pre-training step. Learn unsupervised features from various data sources with an auto-encoder. L_{total} = \\sum_i w_i L_i L_{total} = \\sum_i w_i L_i","title":"Multi-task learning"},{"location":"hybrid/intro/#rtm-radiative-transfer-models","text":"Forward modelling: determine physical laws which govern complex phenomena. Inverse modelling: determine the underlying physical conditions which correspond to a given set of real obtained values.","title":"RTM (Radiative Transfer Models)"},{"location":"hybrid/intro/#prosail","text":"PROSPECT: leaf optical properties model SAIL: Canopy bidirectional reflectance model Inputs (14) Importants (9) non-importants (5) LAI Leaf chlorophyll Biomas ... ------------- ------------------------ -------------------- Ouputs Different wave lengths","title":"Prosail"},{"location":"hybrid/intro/#ideas","text":"Update the weights of the model (neural network) based on how the similarity increase between the weight vector to the input.","title":"Ideas"},{"location":"hybrid/theory/","text":"Theory Latent variables : variables that are not directly observed. They are inferred from other variables that are observed. Useful to reduce dimensionality of data. RKHS (Reproducing Kernel Hilbert Space) KRR (Kernel Ridge Regression): Kernel method. Ridge regression: particular case of a quadratic regularized. Variational Auto-Encoders (VAE) Neural net language: Encoder, decoder and a loss function. Probability model: approximate inference in a latent Gaussian model. source The reconstruction log-likelihood \\log p_{\\phi}(x|y) \\log p_{\\phi}(x|y) tells how effectively the decoder has learned to reconstruct an input x x given its latent representation z z . ELBO (Evidence Lower BOund): to approximate posterior inference Measures of similarity \\mathbf{P} = \\mathbb{P}_{x,y} \\mathbf{P} = \\mathbb{P}_{x,y} the join distribution \\mathbf{Q} = \\mathbb{P}_x \\mathbb{P}_y \\mathbf{Q} = \\mathbb{P}_x \\mathbb{P}_y Marginal distributions MDN (Mixture Density Network): they predict the expected value of a target while also predicting the underlying probability distribution. Requisits: Minimize the negative logarithm of the PDF. To have an output node for each parameter of the distribution's variables. Validate that the distribution's PDF is differentiable. Distance-based: MMD (Maximum Mean Discrepancy): distance between feature means. MMD^2(P,Q) = ||\\mu_P - \\mu_Q||^2 = \\mathbb{E}_X[k(x,x')] + \\mathbb{E}_Y[k(y,y')] + 2\\mathbb{E}_{X,Y}[k(x,y)] MMD^2(P,Q) = ||\\mu_P - \\mu_Q||^2 = \\mathbb{E}_X[k(x,x')] + \\mathbb{E}_Y[k(y,y')] + 2\\mathbb{E}_{X,Y}[k(x,y)] \\text{cov}(\\mathbf{X}, \\mathbf{Y}) = ||K_\\mathbf{x}||_\\mathcal{F} + ||K_\\mathbf{y}||_\\mathcal{F} - 2\\langle \\tilde{K}_\\mathbf{x}, \\tilde{K}_\\mathbf{y} \\rangle_\\mathcal{F} \\text{cov}(\\mathbf{X}, \\mathbf{Y}) = ||K_\\mathbf{x}||_\\mathcal{F} + ||K_\\mathbf{y}||_\\mathcal{F} - 2\\langle \\tilde{K}_\\mathbf{x}, \\tilde{K}_\\mathbf{y} \\rangle_\\mathcal{F} MMD^2 = \\frac{1}{m(m\u22121)}\\sum_i \\sum_j k(x_i,x_j)+ \\frac{1}{n(n\u22121)}\\sum_i \\sum_j k(y_i,y_j)\u2212 \\frac{2}{mn}\\sum_i \\sum_j k(x_i,x_j)k(x_i,y_j) MMD^2 = \\frac{1}{m(m\u22121)}\\sum_i \\sum_j k(x_i,x_j)+ \\frac{1}{n(n\u22121)}\\sum_i \\sum_j k(y_i,y_j)\u2212 \\frac{2}{mn}\\sum_i \\sum_j k(x_i,x_j)k(x_i,y_j) Source \"A Kernel Two-Sample Test\" page 6 HSIC (Hilbert-Schmidt Independence Criterion): measures independence between two distributions. Example of implementation using Kernels . Centering the data in the kernel space: \\hat{K}_x = K_x H \\hat{K}_x = K_x H , where H H is the centering matrix. \\frac{1}{n^2} Tr(K_x H K_y H) \\frac{1}{n^2} Tr(K_x H K_y H) F-divergences: Bregman divergence : measures difference between two data points. Euclidean distance and KLD are instances of it. KLD (Kullback-Leibler Divergence): Scores how one distribution differs from another.","title":"Concepts"},{"location":"hybrid/theory/#theory","text":"Latent variables : variables that are not directly observed. They are inferred from other variables that are observed. Useful to reduce dimensionality of data. RKHS (Reproducing Kernel Hilbert Space) KRR (Kernel Ridge Regression): Kernel method. Ridge regression: particular case of a quadratic regularized. Variational Auto-Encoders (VAE) Neural net language: Encoder, decoder and a loss function. Probability model: approximate inference in a latent Gaussian model. source The reconstruction log-likelihood \\log p_{\\phi}(x|y) \\log p_{\\phi}(x|y) tells how effectively the decoder has learned to reconstruct an input x x given its latent representation z z . ELBO (Evidence Lower BOund): to approximate posterior inference","title":"Theory"},{"location":"hybrid/theory/#measures-of-similarity","text":"\\mathbf{P} = \\mathbb{P}_{x,y} \\mathbf{P} = \\mathbb{P}_{x,y} the join distribution \\mathbf{Q} = \\mathbb{P}_x \\mathbb{P}_y \\mathbf{Q} = \\mathbb{P}_x \\mathbb{P}_y Marginal distributions MDN (Mixture Density Network): they predict the expected value of a target while also predicting the underlying probability distribution. Requisits: Minimize the negative logarithm of the PDF. To have an output node for each parameter of the distribution's variables. Validate that the distribution's PDF is differentiable.","title":"Measures of similarity"},{"location":"hybrid/theory/#distance-based","text":"MMD (Maximum Mean Discrepancy): distance between feature means. MMD^2(P,Q) = ||\\mu_P - \\mu_Q||^2 = \\mathbb{E}_X[k(x,x')] + \\mathbb{E}_Y[k(y,y')] + 2\\mathbb{E}_{X,Y}[k(x,y)] MMD^2(P,Q) = ||\\mu_P - \\mu_Q||^2 = \\mathbb{E}_X[k(x,x')] + \\mathbb{E}_Y[k(y,y')] + 2\\mathbb{E}_{X,Y}[k(x,y)] \\text{cov}(\\mathbf{X}, \\mathbf{Y}) = ||K_\\mathbf{x}||_\\mathcal{F} + ||K_\\mathbf{y}||_\\mathcal{F} - 2\\langle \\tilde{K}_\\mathbf{x}, \\tilde{K}_\\mathbf{y} \\rangle_\\mathcal{F} \\text{cov}(\\mathbf{X}, \\mathbf{Y}) = ||K_\\mathbf{x}||_\\mathcal{F} + ||K_\\mathbf{y}||_\\mathcal{F} - 2\\langle \\tilde{K}_\\mathbf{x}, \\tilde{K}_\\mathbf{y} \\rangle_\\mathcal{F} MMD^2 = \\frac{1}{m(m\u22121)}\\sum_i \\sum_j k(x_i,x_j)+ \\frac{1}{n(n\u22121)}\\sum_i \\sum_j k(y_i,y_j)\u2212 \\frac{2}{mn}\\sum_i \\sum_j k(x_i,x_j)k(x_i,y_j) MMD^2 = \\frac{1}{m(m\u22121)}\\sum_i \\sum_j k(x_i,x_j)+ \\frac{1}{n(n\u22121)}\\sum_i \\sum_j k(y_i,y_j)\u2212 \\frac{2}{mn}\\sum_i \\sum_j k(x_i,x_j)k(x_i,y_j) Source \"A Kernel Two-Sample Test\" page 6 HSIC (Hilbert-Schmidt Independence Criterion): measures independence between two distributions. Example of implementation using Kernels . Centering the data in the kernel space: \\hat{K}_x = K_x H \\hat{K}_x = K_x H , where H H is the centering matrix. \\frac{1}{n^2} Tr(K_x H K_y H) \\frac{1}{n^2} Tr(K_x H K_y H)","title":"Distance-based:"},{"location":"hybrid/theory/#f-divergences","text":"Bregman divergence : measures difference between two data points. Euclidean distance and KLD are instances of it. KLD (Kullback-Leibler Divergence): Scores how one distribution differs from another.","title":"F-divergences:"},{"location":"kernels/intro/","text":"Kernel function Has to satisfy the following properties: Must be symmetrical K(-u) = K(u) K(-u) = K(u) The area under the curve must be equal to one \\int_{-\\infty}^{+\\infty} K(u)du=1 \\int_{-\\infty}^{+\\infty} K(u)du=1 Its values can not be negative K(u) \\geq 0, \\quad \\forall \\quad {-\\infty} < u < {+\\infty} K(u) \\geq 0, \\quad \\forall \\quad {-\\infty} < u < {+\\infty} Types Gaussian kernel K(x) = \\frac{1}{\\sigma\\sqrt{2\\pi}}*e^{\\frac{(x-\\mu)^2}{2\\sigma^2}} K(x) = \\frac{1}{\\sigma\\sqrt{2\\pi}}*e^{\\frac{(x-\\mu)^2}{2\\sigma^2}}","title":"Kernels"},{"location":"kernels/intro/#kernel-function","text":"Has to satisfy the following properties: Must be symmetrical K(-u) = K(u) K(-u) = K(u) The area under the curve must be equal to one \\int_{-\\infty}^{+\\infty} K(u)du=1 \\int_{-\\infty}^{+\\infty} K(u)du=1 Its values can not be negative K(u) \\geq 0, \\quad \\forall \\quad {-\\infty} < u < {+\\infty} K(u) \\geq 0, \\quad \\forall \\quad {-\\infty} < u < {+\\infty}","title":"Kernel function"},{"location":"kernels/intro/#types","text":"Gaussian kernel K(x) = \\frac{1}{\\sigma\\sqrt{2\\pi}}*e^{\\frac{(x-\\mu)^2}{2\\sigma^2}} K(x) = \\frac{1}{\\sigma\\sqrt{2\\pi}}*e^{\\frac{(x-\\mu)^2}{2\\sigma^2}}","title":"Types"}]}